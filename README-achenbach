# download data from this page https://www.ebi.ac.uk/ena/data/view/PRJEB9586, choose the analysis files tab, then the genome that you want

# MITCH WE HAVE aaALL2.txt.gz our annotations file, so skip that, make a region(Africa) vcf, make sure it is sorted lexically,
# annotate with aaALL2.txt.gz, bcf convert,  make a filtered file and make a filtered daf 
## First things first, let's assess the data we gathered
# Lets check the checksums to make sure the files arent corrupted
md5sum -c md5sum

# Look inside one of the files to get familair with what data is within
zcat foo.vcf.gz | less -S

## Now lets prepare the data

# The SGDP data comes as whole genomes; MT, Y, X; Annotated; and in either raw reads or .vcf's. 
# Each file is one individuals complete genome. We want to make 1 file per population (SGDP region).
# We give bcftools a file (*.txt) that tells it which files to merge together (which individuals are in what population)
# Merge files by population (sbatch mergePop.slr)
bcftools merge -o foo.vcf.gz -O z -l fooSGDP.txt

# Looking inside one of the .vcf's with the following command we see how the genome is ordered                    
bcftools query -f '%CHROM\n' foo.vcf.gz | uniq  

# The genome is ordered numerically but the tabpat program we will use wants it ordered like so (lexically)
bcftools query -f '%CHROM\n' foo.vcf.gz | uniq | sort

# Now lets save this order with the merged files
# The first line grabs all the headers and palces it into a file
# The second line grabs everything else but SORTED and adds it to the file (>>)
zcat foo.vcf.gz | grep "^#" > foo-sorted.vcf
zcat foo.vcf.gz | grep -v "^#" | sort -k1,1 -k2,2n >> foo-sorted.vcf

# Because that left us with an uncompressed .vcf be sure to bgzip it
# Bgzip .vcf
bgzip foo-sorted.vcf

# check sorting, lexically?
bcftools query -f'%CHROM\n' foo-sorted.vcf.gz | uniq

# Now lets annotate the .vcf.gz's with our Ancestral Alleles (aa's) 
# We use the AA's from ENSEMBL. These can be found in rogers/data/ancall/.
# Unfortunately the aa files come separated by chromosome.
# Fortunately the following code can organize the aa*.bz files in the same sorting as our SGDP genomes
seq 22 | sort | xargs printf "aa%s.bgz\n"

# See what that produced? the same sorting as the SGDP
# Now that this makes sense lets put all the files into one file with this
# Prepare annotation file
seq 22 | sort | xargs printf "aa%s.bgz\n" | xargs zcat > ~/yourdirectory/aaALL2.txt

# Now before we can add these annotations to our .vcf.gz files we have to bgzip and  index the annotations
# Bgzip and Tabix take our tab delimited .bgz file and indexes it to produce a .bgz.tbi file
# Index annotation file (sbatch aabgzTabix.slr)
bgzip aaALL2.txt
tabix -b 2 -e 2 aaALL2.txt.gz

# To add our annotations to the .vcf.gz we use bcftools
# Add ancestral annotations (aa's) (bash ancall.sh)
bcftools annotate -a aaALL2.txt.gz -h annots.hdr -c CHROM,POS,INFO/AA foo-sorted.vcf.gz > foo-sorted-aa.vcf

# Because that left us with an uncompressed .vcf be sure to bgzip it
# Bgzip .vcf
bgzip foo-sorted-aa.vcf

# Count lines   wcl.slr
2,875,001,522
# Make sure the annotated region vcf file has all the SNPs as original region vcf, LINE COUNTS SHOULD BE EQUAL
comm <(bcftools query -f'%CHROM\t%POS\n' foo-sorted-aa.vcf.gz) <(bcftools query -f'%CHROM\t%POS\n' foo-sorted.vcf.gz) | wc -l
bcftools query -f'%CHROM\t%POS\n' foo-sorted.vcf.gz | wc -l

# Tabix and Tabpat want to play with a .bcf not a .vcf.gz
# Convert to .bcf
bcftools convert -o foo.bcf -O b foo-sorted-aa.vcf.gz

# NOW our final step before makeing the LegoFit input!
# We need to filter based on the SGDP and our colleagues filtering steps.
# Fortunately the SGDP put each position through a filtering process they describe in SI section 6.
# The FL field in the Format column of each genome has a score. This score determiens how many levels of filering the position passed.
# There are 9 levels of filtering and they SGDP suggests we use only sites with a score of 1 or above.
# The code in the FLfilter.py program i've written take out any sites we don't want to use.
# Filter by SGDP FL annotations
bcftools query -f '%CHROM\t%POS\t%REF\t%ALT\t%INFO/AA[\t%GT:%FL]\n' foo-sorted-aa.bcf | python FLfilter.py > foo-sorted-aa-filter.bcf

# Now we want the output from the filtering process to be handed to the daf program, then if we save the output BINGO BANGO!
# Create .daf file
# count lines
bcftools query -f '%CHROM\t%POS\t%REF\t%ALT\t%INFO/AA[\t%GT:%FL]\n' foo-sorted-aa.bcf | python FLfilter.py | daf > foo-sorted-aa-filter.daf
[u1000406@kingspeak2 simons]$ wc -l simonsyri.daf
2219768333 simonsyri.daf

